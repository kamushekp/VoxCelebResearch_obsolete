{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.set_random_seed(1)\n",
    "\n",
    "from vggvox_model import vggvox_model as m\n",
    "\n",
    "from Feature_reader import *\n",
    "from TripletGenerator import *\n",
    "from metrics import *\n",
    "\n",
    "import constants as c\n",
    "\n",
    "from keras.layers import Input, Conv2D, Conv1D, Flatten, MaxPooling2D, AveragePooling2D, Dense, Lambda, Dropout, Dot, Subtract, Add\n",
    "from keras.models import Model, Sequential\n",
    "from keras import backend as K\n",
    "from keras import regularizers, initializers, optimizers,  callbacks, layers, activations\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True  \n",
    "sess = tf.Session(config=config)\n",
    "set_session(sess)\n",
    "\n",
    "train_reader = Feature_reader(3, r\"D:\\VoxCeleb\\dev\")\n",
    "test_reader = Feature_reader(3, r\"D:\\VoxCeleb\\test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.layers.convolutional.Conv2D at 0x1c057d287f0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "internal_model = m()\n",
    "internal_model.load_weights(\"data/model/weights.h5\")\n",
    "\n",
    "for layer in internal_model.layers:\n",
    "    layer.trainable = False  \n",
    "\n",
    "internal_model.layers.pop()\n",
    "\n",
    "external_model = Flatten(name='flatten')(internal_model.layers[-1].output)\n",
    "external_model = Dense(128, name='embedding')(external_model)\n",
    "external_model = layers.LeakyReLU()(external_model)\n",
    "external_model = Dense(128, name='embedding2')(external_model)\n",
    "external_model = layers.LeakyReLU()(external_model)\n",
    "external_model = Lambda(lambda x: K.l2_normalize(x, axis=-1))(external_model)\n",
    "\n",
    "base_model = Model(inputs = internal_model.get_input_at(0), outputs = [external_model])\n",
    "\n",
    "input_shape = c.input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "y_train = np.zeros((batch_size, 2, 1))\n",
    "\n",
    "train_triplet_generator = TripletGenerator(train_reader)\n",
    "\n",
    "def train_batches_generator():\n",
    "    while True:\n",
    "        yield (train_triplet_generator.create_triplets(batch_size), y_train)\n",
    "        \n",
    "val_data = (train_triplet_generator.create_triplets(1024), np.zeros((1024, 2, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def triplet_loss(y_true, y_pred):\n",
    "    \n",
    "    positive_distance = tf.subtract(1.0, y_pred[:, 0, 0])\n",
    "    negative_distance = tf.subtract(1.0, y_pred[:, 1, 0])\n",
    "    loss = (positive_distance - negative_distance) / (positive_distance + negative_distance)\n",
    "    \n",
    "    return K.mean(K.maximum(loss, K.epsilon()))\n",
    "\n",
    "def build_fris_model(base_model, metrics):\n",
    "\n",
    "    positive_example = Input(shape=input_shape)\n",
    "    negative_example = Input(shape=input_shape)\n",
    "    anchor_example = Input(shape=input_shape)\n",
    "\n",
    "    anchor_embedding = base_model(anchor_example)\n",
    "    positive_embedding = base_model(positive_example)\n",
    "    negative_embedding = base_model(negative_example)\n",
    "    \n",
    "    positive_similarity = Dot(axes = -1, normalize = True)([anchor_embedding, positive_embedding])\n",
    "    negative_similarity = Dot(axes = -1, normalize = True)([anchor_embedding, negative_embedding])    \n",
    "    \n",
    "    stacked_dists = Lambda(lambda vects: K.stack(vects, axis=1),name='stacked_dists')([positive_similarity, negative_similarity])\n",
    "    \n",
    "    model = Model(inputs=[anchor_example, positive_example, negative_example], outputs=stacked_dists)\n",
    "    model.compile(optimizer=optimizers.Adam(lr = 0.00001), loss=triplet_loss, metrics=metrics)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_output(m, reader, Id):\n",
    "    fft = reader.get_ids_random_feature(Id)\n",
    "    prediction = m.predict(fft.reshape(1, fft.shape[0], fft.shape[1], 1))\n",
    "    reshaped = np.squeeze(prediction)\n",
    "    return reshaped\n",
    "                           \n",
    "def count_unsimilariry(m, reader, classes_count, class_realizations_count):\n",
    "    \n",
    "    Ids = set([random.choice(reader.ids) for _ in range(classes_count)])\n",
    "    realizations = []\n",
    "    for Id in Ids:\n",
    "        realizations.append([get_random_output(m, reader, Id) for _ in range(class_realizations_count)])\n",
    "                           \n",
    "    return (mean_cos_unsimilarity(realizations, internal = True), mean_cos_unsimilarity(realizations, internal = False))\n",
    "\n",
    "mean_unsimilarity = {'external': [], 'internal': []}\n",
    "\n",
    "class cosine_unsimilariry_callback(callbacks.Callback):\n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        internal, external = count_unsimilariry(base_model, test_reader, 100, 20)\n",
    "        mean_unsimilarity['external'].append(external)        \n",
    "        mean_unsimilarity['internal'].append(internal)\n",
    "        \n",
    "        print(internal)\n",
    "        print(external)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = []\n",
    "fris_model = build_fris_model(base_model, metrics)\n",
    "fris_model.load_weights('models/model050.00.hdf5')\n",
    "\n",
    "def schedule(epoch, lr):\n",
    "    if epoch % 10 == 0:\n",
    "        return lr / 10.0\n",
    "    else:\n",
    "        return lr\n",
    "\n",
    "cb = [cosine_unsimilariry_callback(),\n",
    "      callbacks.ModelCheckpoint(filepath='models/model{epoch:02d}{val_loss:.2f}.hdf5', verbose=1),\n",
    "            callbacks.TerminateOnNaN(),\n",
    "             #callbacks.EarlyStopping(monitor='val_loss', patience=25, verbose=1),\n",
    "             callbacks.TensorBoard(log_dir='logs', write_graph=True, write_grads=True, write_images=True, update_freq='epoch'),\n",
    "             #callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=15, verbose=1)\n",
    "             callbacks.LearningRateScheduler(schedule)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fris_model.fit_generator(train_batches_generator(), steps_per_epoch=70, epochs=200, verbose=1, callbacks=cb, validation_data=val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = create_triplets(test_reader, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.predict(x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.predict(x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.predict(x[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "internal, external = count_unsimilariry(base_model, test_reader, 2, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "internal, external"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fris_model.predict_on_batch(create_triplets(test_reader, 64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = create_triplets(test_reader, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fris_model.predict_on_batch((x[0], )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schedule(21, 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.save('base_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
